---
title: "COVID19-Climate"
output: html_document
editor_options: 
  chunk_output_type: console
---

### Retrieving COVID-19 cases

Started with the repo: https://github.com/imantsm/COVID-19

Import the data: Looking at the Hopkins COVID-19 data that was cloned from https://github.com/CSSEGISandData/COVID-19

```{r}
df_confirmed <- read.csv('./COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')
df_deaths <- read.csv('./COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv')
df_recovered <- read.csv('./COVID-19-master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv')
```

Weather data.
```{r}
df_tMax <- read.csv('./COVID-19-master/csv/tMax.csv')
```

### Retrieving weather data from Dark Sky

Set up Dark Sky API for retreiving weather data and forecasts.
```{r}
library(darksky)

darksky_api_key(force = FALSE)
```

Get current forecast for Tallahassee
```{r}
now <- get_current_forecast(30.4380556, -84.2808333)
print(now)
```

Historical (using Date objects)
```{r}
library(tidyverse)

seq(Sys.Date()-10, Sys.Date(), "1 day") %>% 
  map(~get_forecast_for(30.4380556, -84.2808333, .x)) %>% 
  map_df("hourly") %>% 
  ggplot(aes(x=time, y=temperature)) +
  geom_line()
```

### Working with the {stars} package

https://r-spatial.github.io/stars/articles/stars1.html

```{r}
library(stars)
```

Spatiotemporal arrays are stored in objects of class stars; methods for class stars currently available are
```{r}
methods(class = "stars")
```

{tidyverse} methods are only visible after loading package {tidyverse}.

#### Reading a satellite image

We can read a satellite image through GDAL, e.g. from a GeoTIFF file in the package:
```{r}
tif <- system.file("tif/L7_ETMs.tif", package = "stars")
x <- read_stars(tif)
plot(x)
```

We see that the image is geographically referenced (has coordinate values along axes), and that the object returned (x) has three dimensions called x, y and band, and has one attribute.
```{r}
x
```

Each dimension has a name; the meaning of the fields of a single dimension are:

field	| meaning
------|--------
from |	the origin index (1)
to|	the final index (dim(x)[i])
offset |	the start value for this dimension (pixel boundary), if regular
delta	| the step (pixel, cell) size for this dimension, if regular
refsys |	the reference system, or proj4string
point	| logical; whether cells refer to points, or intervals
values |	the sequence of values for this dimension (e.g., geometries), if irregular

This means that for an index i (starting at i = 1) along a certain dimension, the corresponding dimension value (coordinate, time) is offset+ (i - 1) x delta. This value then refers to the start (edge) of the cell or interval; in order to get the interval middle or cell center, one needs to add half an offset.

Dimension band is a simple sequence from 1 to 6. Since bands refer to colors, one could put their wavelength values in the values field.

For this particular dataset (and most other raster datasets), we see that offset for dimension y is negative: this means that consecutive array values have decreasing 𝑦 values: cell indexes increase from top to bottom, in the direction opposite to the 𝑦 axis.

The function `read_stars()` reads all bands from a raster dataset, or optionally a subset of raster datasets, into a single stars array structure. While doing so, raster values (often UINT8 or UINT16) are converted to double (numeric) values, and scaled back to their original values if needed if the file encodes the scaling parameters.

The data structure stars is a generalisation of the `tbl_cube()` found in {cubelyr}; we can convert to that by

#### Switching attributes to dimensions and back
```{r}
( x.spl <- split(x, "band") )

merge(x.spl)
```

We see that the newly created dimension lost its name, and the single attribute got a default name. We can set attribute names with `setNames()`, and dimension names and values with `st_set_dimensions()`.
```{r}
library(dplyr)

merge(x.spl) %>% 
  setNames(names(x)) %>%
  st_set_dimensions(3, values = paste0("band", 1:6)) %>%
  st_set_dimensions(names = c("x", "y", "band"))
```

#### Subsetting
Besides the tidyverse subsetting and selection operators explained in this vignette, we can also use [ and [[. Since stars objects are a list of arrays with a metadata table describing dimensions, list extraction (and assignment) works as expected:
```{r}
class(x[[1]])
dim(x[[1]])

x$two = 2 * x[[1]]
x
```

At this level, we can work with array objects directly.

The stars subset operator [ works a bit different: its

* first argument selects attributes
* second argument selects the first dimension
* third argument selects the second dimension, etc
Thus,
```{r}
x["two", 1:10, , 2:4]
```

Alternatively, when [ is given a single argument of class sf, sfc or bbox, [ will work as a crop operator:
```{r}
circle <- st_sfc(st_buffer(st_point(c(293749.5, 9115745)), 400), crs = st_crs(x))
plot(x[circle][, , , 1], reset = FALSE)
plot(circle, col = NA, border = 'red', add = TRUE, lwd = 2)
```

### Reading a raster time series: NetCDF
Another example is when we read raster time series model outputs in a NetCDF file, e.g. by
```{r}
w <- system.file("nc/bcsd_obs_1999.nc", package = "stars") %>%
    read_stars("data/full_data_daily_2013.nc")
```

We see that
```{r}
w
```

For this dataset we can see that

* variables have units associated (and a wrong unit, C is assigned to temperature)
* time is now a dimension, with proper units and time steps

#### Reading datasets from multiple files
Model data are often spread across many files. An example of a 0.25 degree grid, global daily sea surface temperature product is found here; a subset of the 1981 data was downloaded from here.

We read the data by giving `read_stars()` a vector with character names:
```{r}
x <- c(
"avhrr-only-v2.19810901.nc",
"avhrr-only-v2.19810902.nc",
"avhrr-only-v2.19810903.nc",
"avhrr-only-v2.19810904.nc",
"avhrr-only-v2.19810905.nc",
"avhrr-only-v2.19810906.nc",
"avhrr-only-v2.19810907.nc",
"avhrr-only-v2.19810908.nc",
"avhrr-only-v2.19810909.nc"
)
```
```{r}
#install.packages("starsdata", repos = "http://pebesma.staff.ifgi.de", type = "source") 

file_list = system.file(paste0("netcdf/", x), package = "starsdata")
(y <- read_stars(file_list, quiet = TRUE))
```

Next, we select sea surface temperature (sst), and drop the singular zlev (depth) dimension using adrop:
```{r}
library(dplyr)
library(abind)

z <- y %>% select(sst) %>% adrop()
```

We can now graph the sea surface temperature (SST) using ggplot, which needs data in a long table form, and without units.
```{r}
library(ggplot2)
library(viridis)
library(ggthemes)

ggplot() +  
  geom_stars(data = z[1], alpha = 0.8, downsample = c(10, 10, 1)) + 
  facet_wrap("time") +
  scale_fill_viridis() +
  coord_equal() +
  theme_map() +
  theme(legend.position = "bottom") +
  theme(legend.key.width = unit(2, "cm"))
```

### Vector data cube example
Like `tbl_cube`, {stars} arrays have no limits to the number of dimensions they handle. An example is the origin-destination (OD) matrix, by time and travel mode.

#### OD: space x space x travel mode x time x time
We create a 5-dimensional matrix of traffic between regions, by day, by time of day, and by travel mode. Having day and time of day each as dimension is an advantage when we want to compute patterns over the day, for a certain period.
```{r}
nc <- st_read(system.file("gpkg/nc.gpkg", package = "sf")) 
to <- from <- st_geometry(nc) # 100 polygons: O and D regions
mode <- c("car", "bike", "foot") # travel mode
day <- 1:100 # arbitrary

library(units)

units(day) <- as_units("days since 2015-01-01")
hour <- set_units(0:23, h) # hour of day
dims <- st_dimensions(origin = from, destination = to, mode = mode, day = day, hour = hour)
(n = dim(dims))

traffic = array(rpois(prod(n), 10), dim = n) # simulated traffic counts
(st = st_as_stars(list(traffic = traffic),  dimensions = dims))
```

This array contains the simple feature geometries of origin and destination so that we can directly plot every slice without additional table joins. If we want to represent such an array as a tbl_cube, the simple feature geometry dimensions need to be replaced by indexes:
```{r}
st %>% as.tbl_cube()
```

The following demonstrates how dplyr can filter bike travel, and compute mean bike traffic by hour of day:
```{r}
b <- st %>% 
  as.tbl_cube() %>%
  filter(mode == "bike") %>%
  group_by(hour) %>%
  summarise(traffic = mean(traffic)) %>%
  as.data.frame()
require(ggforce) # for plotting a units variable
## Loading required package: ggforce
ggplot() +  
  geom_line(data = b, aes(x = hour, y = traffic))
```

Do this for the weather data above.
```{r}
df_tMax <- read.csv('./COVID-19-master/csv/tMax.csv')

sf_tMax <- st_as_sf(x = df_tMax, 
                        coords = c("Lat", "Long"),
                        crs = 4326)

sf_deaths <- st_as_sf(x = df_deaths,
                      coords = c("Lat", "Long"),
                      crs = 4326)
```

```{r}
to <- st_geometry(sf_tMax) # 442 locations
day <- 1:74 # arbitrary

units(day) <- as_units("days since 2019-12-31")

dims <- st_dimensions(location = to, day = day)
( n = dim(dims) )

tMax <- array(df_tMax[1:nrow(df_tMax), 5:ncol(df_tMax)])
( st <- st_as_stars(list(tMax = tMax),  dimensions = dims) )
```

```{r}
st %>% as.tbl_cube()
```

```{r}
library(ggforce) # for plotting a units variable
b <- st %>% 
  as.tbl_cube() %>%
  group_by(day) %>%
  summarise(tMax = mean(tMax)) %>%
  as.data.frame()
ggplot() +  
  geom_line(data = b, aes(x = day, y = tMax))
```

Repeat for deaths
```{r}
to <- st_geometry(sf_deaths)
day <- 1:53
units(day) <- as_units("days since 2019-12-31")

dims <- st_dimensions(location = to, day = day)
( n = dim(dims) )
deaths <- array(df_deaths[1:nrow(df_deaths), 5:ncol(df_deaths)])
( st <- st_as_stars(list(deaths = deaths),  dimensions = dims) )

b <- st %>% 
  as.tbl_cube() %>%
  group_by(day) %>%
  summarise(deaths = sum(deaths)) %>%
  as.data.frame()
ggplot() +  
  geom_line(data = b, aes(x = day, y = deaths))
```